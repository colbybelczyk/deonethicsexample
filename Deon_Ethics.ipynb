{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **DEON ETHICS CHECKLIST**"
      ],
      "metadata": {
        "id": "VQLk8E99bA1c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1**: Install Deon Library."
      ],
      "metadata": {
        "id": "XQ3_EJ5oUjVW"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umoTt7LeUYcS",
        "outputId": "7b94e6e8-fd56-4a65-8210-66dc1917cb95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting deon\n",
            "  Downloading deon-0.3.0.tar.gz (26 kB)\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: beautifulsoup4>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from deon) (4.12.3)\n",
            "Requirement already satisfied: click>=6.7 in /usr/local/lib/python3.10/dist-packages (from deon) (8.1.7)\n",
            "Requirement already satisfied: pyyaml>=3.13 in /usr/local/lib/python3.10/dist-packages (from deon) (6.0.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4>=4.6.1->deon) (2.6)\n",
            "Building wheels for collected packages: deon\n",
            "  Building wheel for deon (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for deon: filename=deon-0.3.0-py3-none-any.whl size=21352 sha256=1161b4095b5b5e4f300be85ec2ae8f242c6eb1fae6e351ae200e9edac5fb9e41\n",
            "  Stored in directory: /root/.cache/pip/wheels/65/8e/b0/6215389003a488515cb8287265bc54506a636bbf043d79c2b8\n",
            "Successfully built deon\n",
            "Installing collected packages: deon\n",
            "Successfully installed deon-0.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install deon\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2:  Check Available Commands**"
      ],
      "metadata": {
        "id": "olNmm4TAV_7x"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!deon --help\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuyL0khZVcyn",
        "outputId": "f26fb198-3843-439d-e7a5-f7837b7a6e35"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Usage: deon [OPTIONS]\n",
            "\n",
            "  Easily create an ethics checklist for your data science project.\n",
            "\n",
            "  The checklist will be printed to standard output by default. Use the\n",
            "  --output option to write to a file instead.\n",
            "\n",
            "Options:\n",
            "  -l, --checklist PATH  Override default checklist file with a path to a\n",
            "                        custom checklist.yml file.\n",
            "  -f, --format TEXT     Output format. Default is \"markdown\". Can be one of\n",
            "                        [ascii, html, jupyter, markdown, rmarkdown, rst].\n",
            "                        Ignored and file extension used if --output is passed.\n",
            "  -o, --output PATH     Output file path. Extension can be one of [.txt,\n",
            "                        .html, .ipynb, .md, .rmd, .rst]. The checklist is\n",
            "                        appended if the file exists.\n",
            "  -w, --overwrite       Overwrite output file if it exists. Default is False,\n",
            "                        which will append to existing file.\n",
            "  -m, --multicell       For use with Jupyter format only. Write checklist with\n",
            "                        multiple cells, one item per cell. Default is False,\n",
            "                        which will write the checklist in a single cell.\n",
            "  --help                Show this message and exit.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Create the Deon Checklist**"
      ],
      "metadata": {
        "id": "qW2v-c_aWFKm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate the checklist using the Deon CLI in markdown format\n",
        "!deon --output wildfire_ethics_checklist.md --format markdown\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySGNm_I_V8l7",
        "outputId": "9c6abda4-6af2-4c09-9e5c-00b75f51acae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checklist successfully written to file wildfire_ethics_checklist.md.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 4: Read and Display the Checklist**"
      ],
      "metadata": {
        "id": "mS0IFjo8WPNh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Read and display the generated checklist\n",
        "with open('wildfire_ethics_checklist.md', 'r') as file:\n",
        "    checklist_content = file.read()\n",
        "\n",
        "print(checklist_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cJ7D6t17WMlp",
        "outputId": "28220353-0fb0-460a-e573-9782a0b35b9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Data Science Ethics Checklist\n",
            "\n",
            "[![Deon badge](https://img.shields.io/badge/ethics%20checklist-deon-brightgreen.svg?style=popout-square)](http://deon.drivendata.org/)\n",
            "\n",
            "## A. Data Collection\n",
            " - [ ] **A.1 Informed consent**: If there are human subjects, have they given informed consent, where subjects affirmatively opt-in and have a clear understanding of the data uses to which they consent?\n",
            " - [ ] **A.2 Collection bias**: Have we considered sources of bias that could be introduced during data collection and survey design and taken steps to mitigate those?\n",
            " - [ ] **A.3 Limit PII exposure**: Have we considered ways to minimize exposure of personally identifiable information (PII) for example through anonymization or not collecting information that isn't relevant for analysis?\n",
            " - [ ] **A.4 Downstream bias mitigation**: Have we considered ways to enable testing downstream results for biased outcomes (e.g., collecting data on protected group status like race or gender)?\n",
            "\n",
            "## B. Data Storage\n",
            " - [ ] **B.1 Data security**: Do we have a plan to protect and secure data (e.g., encryption at rest and in transit, access controls on internal users and third parties, access logs, and up-to-date software)?\n",
            " - [ ] **B.2 Right to be forgotten**: Do we have a mechanism through which an individual can request their personal information be removed?\n",
            " - [ ] **B.3 Data retention plan**: Is there a schedule or plan to delete the data after it is no longer needed?\n",
            "\n",
            "## C. Analysis\n",
            " - [ ] **C.1 Missing perspectives**: Have we sought to address blindspots in the analysis through engagement with relevant stakeholders (e.g., checking assumptions and discussing implications with affected communities and subject matter experts)?\n",
            " - [ ] **C.2 Dataset bias**: Have we examined the data for possible sources of bias and taken steps to mitigate or address these biases (e.g., stereotype perpetuation, confirmation bias, imbalanced classes, or omitted confounding variables)?\n",
            " - [ ] **C.3 Honest representation**: Are our visualizations, summary statistics, and reports designed to honestly represent the underlying data?\n",
            " - [ ] **C.4 Privacy in analysis**: Have we ensured that data with PII are not used or displayed unless necessary for the analysis?\n",
            " - [ ] **C.5 Auditability**: Is the process of generating the analysis well documented and reproducible if we discover issues in the future?\n",
            "\n",
            "## D. Modeling\n",
            " - [ ] **D.1 Proxy discrimination**: Have we ensured that the model does not rely on variables or proxies for variables that are unfairly discriminatory?\n",
            " - [ ] **D.2 Fairness across groups**: Have we tested model results for fairness with respect to different affected groups (e.g., tested for disparate error rates)?\n",
            " - [ ] **D.3 Metric selection**: Have we considered the effects of optimizing for our defined metrics and considered additional metrics?\n",
            " - [ ] **D.4 Explainability**: Can we explain in understandable terms a decision the model made in cases where a justification is needed?\n",
            " - [ ] **D.5 Communicate bias**: Have we communicated the shortcomings, limitations, and biases of the model to relevant stakeholders in ways that can be generally understood?\n",
            "\n",
            "## E. Deployment\n",
            " - [ ] **E.1 Redress**: Have we discussed with our organization a plan for response if users are harmed by the results (e.g., how does the data science team evaluate these cases and update analysis and models to prevent future harm)?\n",
            " - [ ] **E.2 Roll back**: Is there a way to turn off or roll back the model in production if necessary?\n",
            " - [ ] **E.3 Concept drift**: Do we test and monitor for concept drift to ensure the model remains fair over time?\n",
            " - [ ] **E.4 Unintended use**: Have we taken steps to identify and prevent unintended uses and abuse of the model and do we have a plan to monitor these once the model is deployed?\n",
            "\n",
            "*Data Science Ethics Checklist generated with [deon](http://deon.drivendata.org).*\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Customize the checklist f**or your specific project, in this case the project is the prediction of forest wild fires, the input variables are Temperture, Humidify, Wind speed, Rainfall, Fuel Moisture, Vegetation type, Slope, Region. The output variables are size, duration, suppresion cost and fire occurrence"
      ],
      "metadata": {
        "id": "B2lEEF2xWXwm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Customized Deon Ethics Checklist for Forest Wildfire Prediction Model\n",
        "\n",
        "custom_checklist = \"\"\"\n",
        "# Ethics Checklist for Forest Wildfire Prediction Model\n",
        "\n",
        "## 1. Data Collection\n",
        "- **Input Variables**: Temperature, Humidity, Wind Speed, Rainfall, Fuel Moisture, Vegetation Type, Slope, Region\n",
        "- **Output Variables**: Fire Size, Fire Duration, Suppression Cost, Fire Occurrence\n",
        "- Are the data sources, such as weather, vegetation, and geographic data, properly licensed and legally available?\n",
        "- Has any sensitive information, such as private property or personal location data, been anonymized?\n",
        "- Have you obtained consent for data collected from private or proprietary sources, such as satellite imagery or drone footage?\n",
        "\n",
        "## 2. Fairness & Justice\n",
        "- How will you ensure that the model’s predictions are fair and do not disproportionately affect specific regions or communities (e.g., indigenous lands, rural areas)?\n",
        "- What biases might exist in the historical data (e.g., underreporting of fires in certain regions), and how will you address these to ensure the model does not unfairly target or neglect specific areas?\n",
        "- How will you balance fairness in handling both false positives (predicting a fire where there is none) and false negatives (failing to predict a fire)?\n",
        "- Have you tested the model across different regions to ensure consistent performance across various forest types (tropical, temperate, etc.)?\n",
        "\n",
        "## 3. Transparency\n",
        "- How will you ensure transparency about the data sources, algorithms, and decision-making process of the model?\n",
        "- What information will you make available to government agencies, the public, and environmental organizations?\n",
        "- How will you communicate the model’s predictions and limitations to decision-makers so that they understand the risks involved?\n",
        "- How will you explain false positives and false negatives to the affected communities or stakeholders, especially during critical events like evacuations?\n",
        "\n",
        "## 4. Privacy\n",
        "- How will you ensure the privacy of individuals whose data might be inadvertently captured (e.g., campers, rural residents) through satellite images, drones, or weather stations?\n",
        "- What steps will you take to prevent the misuse of this data, especially in terms of tracking human activities in forest areas without their consent?\n",
        "- If external data sources, such as drones or surveillance tools, are integrated into the model, how will you balance the need for accurate predictions with protecting individual privacy?\n",
        "\n",
        "## 5. Accountability\n",
        "- Who will be held accountable if the model incorrectly predicts a wildfire, resulting in unnecessary evacuations or failure to prevent a disaster?\n",
        "- What system will you establish to monitor and adjust the model over time, ensuring it adapts to changing environmental and climate conditions?\n",
        "- How will you communicate accountability measures to the public, especially in high-risk areas where wildfire prediction is critical?\n",
        "\n",
        "## 6. Inclusivity\n",
        "- How will you ensure the model includes diverse data from different types of forests (e.g., tropical, temperate) and regions, especially those that may be underrepresented in historical data collection?\n",
        "- How will you ensure the model accounts for the needs of different communities, including vulnerable populations such as indigenous groups or rural residents who have unique relationships with the land?\n",
        "- If certain regions or communities lack sufficient data (e.g., underreporting, lack of resources), how will you address this to avoid biased predictions?\n",
        "\n",
        "## 7. Sustainability\n",
        "- How will the model’s predictions affect long-term forestry practices, land management, and firefighting strategies over time?\n",
        "- How will you ensure the model remains sustainable, considering the evolving nature of climate change and its effects on wildfire patterns?\n",
        "- What are the broader social and environmental implications if this model becomes widely adopted (e.g., impacts on land use, deforestation policies, wildlife conservation)?\n",
        "\"\"\"\n",
        "\n",
        "# Save the customized checklist to a new markdown file\n",
        "with open('custom_wildfire_ethics_checklist.md', 'w') as file:\n",
        "    file.write(custom_checklist)\n",
        "\n",
        "print(\"Custom ethics checklist saved as 'custom_wildfire_ethics_checklist.md'\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8BgmYkqsXFu-",
        "outputId": "2c99d0ee-f6a3-476b-d45a-d8febde6be8c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom ethics checklist saved as 'custom_wildfire_ethics_checklist.md'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Steps to host this in huggingface**"
      ],
      "metadata": {
        "id": "ZGU8V45AaHJl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 1: Upload the custom file and ethics checklist to hugging face"
      ],
      "metadata": {
        "id": "kcHl6D4UaWrf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Step 2: Add an app.py file with the information below"
      ],
      "metadata": {
        "id": "ZzvLSVV8afJ5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr\n",
        "\n",
        "# Markdown content\n",
        "md_content = \"\"\"\n",
        "# Ethics Checklist for Forest Wildfire Prediction Model\n",
        "\n",
        "## 1. Data Collection\n",
        "- **Input Variables**: Temperature, Humidity, Wind Speed, Rainfall, Fuel Moisture, Vegetation Type, Slope, Region\n",
        "- **Output Variables**: Fire Size, Fire Duration, Suppression Cost, Fire Occurrence\n",
        "- Are the data sources, such as weather, vegetation, and geographic data, properly licensed and legally available?\n",
        "- Has any sensitive information, such as private property or personal location data, been anonymized?\n",
        "- Have you obtained consent for data collected from private or proprietary sources, such as satellite imagery or drone footage?\n",
        "\n",
        "## 2. Fairness & Justice\n",
        "- How will you ensure that the model’s predictions are fair and do not disproportionately affect specific regions or communities (e.g., indigenous lands, rural areas)?\n",
        "- What biases might exist in the historical data (e.g., underreporting of fires in certain regions), and how will you address these to ensure the model does not unfairly target or neglect specific areas?\n",
        "- How will you balance fairness in handling both false positives (predicting a fire where there is none) and false negatives (failing to predict a fire)?\n",
        "- Have you tested the model across different regions to ensure consistent performance across various forest types (tropical, temperate, etc.)?\n",
        "\n",
        "## 3. Transparency\n",
        "- How will you ensure transparency about the data sources, algorithms, and decision-making process of the model?\n",
        "- What information will you make available to government agencies, the public, and environmental organizations?\n",
        "- How will you communicate the model’s predictions and limitations to decision-makers so that they understand the risks involved?\n",
        "- How will you explain false positives and false negatives to the affected communities or stakeholders, especially during critical events like evacuations?\n",
        "\n",
        "## 4. Privacy\n",
        "- How will you ensure the privacy of individuals whose data might be inadvertently captured (e.g., campers, rural residents) through satellite images, drones, or weather stations?\n",
        "- What steps will you take to prevent the misuse of this data, especially in terms of tracking human activities in forest areas without their consent?\n",
        "- If external data sources, such as drones or surveillance tools, are integrated into the model, how will you balance the need for accurate predictions with protecting individual privacy?\n",
        "\n",
        "## 5. Accountability\n",
        "- Who will be held accountable if the model incorrectly predicts a wildfire, resulting in unnecessary evacuations or failure to prevent a disaster?\n",
        "- What system will you establish to monitor and adjust the model over time, ensuring it adapts to changing environmental and climate conditions?\n",
        "- How will you communicate accountability measures to the public, especially in high-risk areas where wildfire prediction is critical?\n",
        "\n",
        "## 6. Inclusivity\n",
        "- How will you ensure the model includes diverse data from different types of forests (e.g., tropical, temperate) and regions, especially those that may be underrepresented in historical data collection?\n",
        "- How will you ensure the model accounts for the needs of different communities, including vulnerable populations such as indigenous groups or rural residents who have unique relationships with the land?\n",
        "- If certain regions or communities lack sufficient data (e.g., underreporting, lack of resources), how will you address this to avoid biased predictions?\n",
        "\n",
        "## 7. Sustainability\n",
        "- How will the model’s predictions affect long-term forestry practices, land management, and firefighting strategies over time?\n",
        "- How will you ensure the model remains sustainable, considering the evolving nature of climate change and its effects on wildfire patterns?\n",
        "- What are the broader social and environmental implications if this model becomes widely adopted (e.g., impacts on land use, deforestation policies, wildlife conservation)?\n",
        "\"\"\"\n",
        "\n",
        "def display_markdown():\n",
        "    return md_content\n",
        "\n",
        "# Create a Gradio interface\n",
        "iface = gr.Interface(fn=display_markdown, inputs=[], outputs=\"markdown\")\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "id": "_xy54_onac_t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "outputId": "234a1362-3120-4e92-df5c-a019555d87f5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'gradio'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-bd77dd8d7c1f>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgradio\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mgr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Markdown content\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m md_content = \"\"\"\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Ethics Checklist for Forest Wildfire Prediction Model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'gradio'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **ETHICS DataCAD**"
      ],
      "metadata": {
        "id": "jU8bPyCzbFBl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "An Ethics DataCard is a documentation tool designed to provide a detailed, transparent account of the ethical considerations surrounding a dataset or model. It aims to highlight key aspects such as data collection, privacy, biases, fairness, accountability, and societal impact, ensuring that stakeholders understand the potential ethical risks and implications. Unlike Deon, which offers a predefined checklist for ethics in data science, Ethics DataCards are more customizable and focus on a narrative approach, allowing for more specific insights into the dataset or model's lifecycle. The advantage of DataCards lies in their flexibility and depth, enabling project-specific ethical assessments, while Deon's checklist approach offers a quick, standardized framework. However, Deon may be easier to implement for teams seeking a simple, checklist-based structure, whereas DataCards require more detailed input and customization, making them more resource-intensive but richer in context."
      ],
      "metadata": {
        "id": "L-fkfwuUgOCZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 1: Define the Ethics DataCad contents**\n"
      ],
      "metadata": {
        "id": "UB9OxTlsfhR6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "import gradio as gr\n",
        "\n",
        "# Ethics DataCard content for forest wildfire prediction model\n",
        "datacard_content = \"\"\"\n",
        "# Ethics DataCard for Forest Wildfire Prediction Model\n",
        "\n",
        "## Dataset Overview\n",
        "- **Input Variables**: Temperature, Humidity, Wind Speed, Rainfall, Fuel Moisture, Vegetation Type, Slope, Region\n",
        "- **Output Variables**: Fire Size, Fire Duration, Suppression Cost, Fire Occurrence\n",
        "\n",
        "## Data Collection Process\n",
        "- Data sources include weather data, satellite imagery, vegetation reports, and topographical data.\n",
        "- Data is collected from public and licensed sources, ensuring proper consent and anonymization of any private information (e.g., personal property location).\n",
        "\n",
        "## Bias Considerations\n",
        "- **Potential Bias**: Historical data may underreport wildfires in remote or underserved regions (e.g., rural or indigenous lands).\n",
        "- **Mitigation**: The model is designed to minimize biases by cross-referencing multiple data sources and continuously monitoring the data collection process to ensure it includes diverse geographic regions.\n",
        "\n",
        "## Fairness & Justice\n",
        "- The model has been trained to predict wildfires across various geographic regions and forest types. Efforts have been made to avoid disproportionate impacts on vulnerable communities (e.g., rural populations, indigenous lands).\n",
        "- Special attention is given to reducing false positives (unnecessary evacuations) and false negatives (failure to predict real wildfires), balancing the risk for all stakeholders.\n",
        "\n",
        "## Privacy and Security\n",
        "- Satellite data, weather station information, and geographic data are used, with efforts to anonymize any personal information inadvertently captured (e.g., campers, property owners).\n",
        "- No social media or surveillance data is used without explicit consent.\n",
        "\n",
        "## Sustainability and Environmental Impact\n",
        "- The model aims to assist in sustainable land management and wildfire mitigation strategies by improving early prediction and reducing the severity of wildfires.\n",
        "- It supports long-term environmental sustainability by informing decisions around land use, deforestation, and conservation practices.\n",
        "\n",
        "## Model Limitations\n",
        "- The model's accuracy may vary depending on the region and the quality of data available.\n",
        "- There are limitations to predicting wildfires in regions with insufficient historical data, leading to potential inaccuracies.\n",
        "- The model is regularly updated to incorporate new climate data and evolving environmental conditions.\n",
        "\n",
        "## Accountability and Transparency\n",
        "- The development team will monitor the model for performance over time, ensuring that it adapts to new data and environmental shifts.\n",
        "- Stakeholders (e.g., firefighting agencies, local governments) will be informed of the model’s limitations, ensuring proper interpretation of the predictions.\n",
        "- False predictions will be communicated to stakeholders, with a process in place for continuous feedback and model improvement.\n",
        "\n",
        "## Societal Impact\n",
        "- The model is designed to protect both human lives and the environment by enabling better planning and response to wildfire threats.\n",
        "- It has the potential to inform policy changes in land management, conservation, and emergency response strategies.\n",
        "\"\"\"\n",
        "\n",
        "# Function to display the DataCard\n",
        "def display_datacard():\n",
        "    return datacard_content\n",
        "\n",
        "# Gradio interface to display the ethics DataCard\n",
        "iface = gr.Interface(fn=display_datacard, inputs=[], outputs=\"markdown\")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "iface.launch()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "mE2UyKrwfskN",
        "outputId": "80fa3674-19c3-4c10-af6f-67c8e4b20ff0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-5.5.0-py3-none-any.whl.metadata (16 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
            "  Downloading fastapi-0.115.5-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.4.2 (from gradio)\n",
            "  Downloading gradio_client-1.4.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.2)\n",
            "Requirement already satisfied: huggingface-hub>=0.25.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.26.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Collecting markupsafe~=2.0 (from gradio)\n",
            "  Downloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.10.11)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (11.0.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.9.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart==0.0.12 (from gradio)\n",
            "  Downloading python_multipart-0.0.12-py3-none-any.whl.metadata (1.9 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting safehttpx<1.0,>=0.1.1 (from gradio)\n",
            "  Downloading safehttpx-0.1.1-py3-none-any.whl.metadata (4.1 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
            "  Downloading starlette-0.41.2-py3-none-any.whl.metadata (6.0 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.32.0-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.4.2->gradio) (2024.10.0)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.4.2->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.6)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (3.16.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.25.1->gradio) (4.66.6)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.23.4)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.4.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.3)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-5.5.0-py3-none-any.whl (56.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.7/56.7 MB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.4.2-py3-none-any.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.8/319.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.12-py3-none-any.whl (23 kB)\n",
            "Downloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading fastapi-0.115.5-py3-none-any.whl (94 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-2.1.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Downloading ruff-0.7.3-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.0/11.0 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading safehttpx-0.1.1-py3-none-any.whl (8.4 kB)\n",
            "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.41.2-py3-none-any.whl (73 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m73.3/73.3 kB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.32.0-py3-none-any.whl (63 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m9.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, uvicorn, tomlkit, semantic-version, ruff, python-multipart, markupsafe, ffmpy, aiofiles, starlette, safehttpx, gradio-client, fastapi, gradio\n",
            "  Attempting uninstall: markupsafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.115.5 ffmpy-0.4.0 gradio-5.5.0 gradio-client-1.4.2 markupsafe-2.1.5 pydub-0.25.1 python-multipart-0.0.12 ruff-0.7.3 safehttpx-0.1.1 semantic-version-2.10.0 starlette-0.41.2 tomlkit-0.12.0 uvicorn-0.32.0 websockets-12.0\n",
            "Running Gradio in a Colab notebook requires sharing enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://1d028fd2c035cc46d0.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://1d028fd2c035cc46d0.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 2: Define requirements file**"
      ],
      "metadata": {
        "id": "5IbFmxDrf252"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "gradio\n"
      ],
      "metadata": {
        "id": "Mv5ZYNTcf_gq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Step 3: Upload the app.py file and requirements.txt file to huggingface**"
      ],
      "metadata": {
        "id": "TSlG4_tTgCtq"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "LdmkKJETaa4N"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}